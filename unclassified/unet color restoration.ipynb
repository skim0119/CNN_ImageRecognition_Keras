{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 8-1 컬러를 복원하는 UNET\n",
    "\n",
    "<img width=\"640\" alt=\"U-Net CNN Image Segmentation\" src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\">\n",
    "\n",
    "Code Reference:\n",
    "- [keraspp] (https://github.com/jskDr/keraspp)\n",
    "- https://github.com/4g/unet-color\n",
    "\n",
    "Implementation Reference:\n",
    "- https://github.com/phillipi/pix2pix\n",
    "\n",
    "Theory Reference:\n",
    "- https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\n",
    "- https://arxiv.org/abs/1505.04597\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skim0119/venv/GenP3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/skim0119/venv/GenP3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras import models, backend\n",
    "from keras import datasets, utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, \\\n",
    "    UpSampling2D, BatchNormalization, Concatenate, Activation\n",
    "    \n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32) (50000, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "class DATA():\n",
    "    def __init__(self, in_ch=None):\n",
    "        (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "        if x_train.ndim == 4:\n",
    "            if backend.image_data_format() == 'channels_first':\n",
    "                n_ch, img_rows, img_cols = x_train.shape[1:]\n",
    "            else:\n",
    "                img_rows, img_cols, n_ch = x_train.shape[1:]\n",
    "        else:\n",
    "            img_rows, img_cols = x_train.shape[1:]\n",
    "            n_ch = 1\n",
    "        # in_ch can be 1 for changing BW to color image using UNet\n",
    "        in_ch = n_ch if in_ch is None else in_ch\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        def RGB2Gray(X, fmt):\n",
    "            if fmt == 'channels_first':\n",
    "                R = X[:, 0:1]\n",
    "                G = X[:, 1:2]\n",
    "                B = X[:, 2:3]\n",
    "            else:  # \"channels_last\n",
    "                R = X[..., 0:1]\n",
    "                G = X[..., 1:2]\n",
    "                B = X[..., 2:3]\n",
    "            return 0.299 * R + 0.587 * G + 0.114 * B\n",
    "        \n",
    "        def RGB2RG(x_train_out, x_test_out, fmt):\n",
    "            if fmt == 'channels_first':\n",
    "                x_train_in = x_train_out[:, :2]\n",
    "                x_test_in = x_test_out[:, :2]\n",
    "            else:\n",
    "                x_train_in = x_train_out[..., :2]\n",
    "                x_test_in = x_test_out[..., :2]      \n",
    "            return x_train_in, x_test_in\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], n_ch, img_rows, img_cols)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], n_ch, img_rows, img_cols)\n",
    "            input_shape = (in_ch, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], img_rows, img_cols, n_ch)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], img_rows, img_cols, n_ch)\n",
    "            input_shape = (img_rows, img_cols, in_ch)\n",
    "\n",
    "        if in_ch == 1 and n_ch == 3:\n",
    "            x_train_in = RGB2Gray(x_train_out, backend.image_data_format())\n",
    "            x_test_in = RGB2Gray(x_test_out, backend.image_data_format())\n",
    "        elif in_ch == 2 and n_ch == 3:\n",
    "            # print(in_ch, n_ch)\n",
    "            x_train_in, x_test_in = RGB2RG(x_train_out, x_test_out, backend.image_data_format())\n",
    "        else:\n",
    "            x_train_in = x_train_out\n",
    "            x_test_in = x_test_out\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.x_train_in, self.x_train_out = x_train_in, x_train_out\n",
    "        self.x_test_in, self.x_test_out = x_test_in, x_test_out\n",
    "        self.n_ch = n_ch\n",
    "        self.in_ch = in_ch\n",
    "        \n",
    "data = DATA(1)\n",
    "print(data.input_shape, data.x_train_in.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# unet_conv_cifar10rgb_mc.py\n",
    "# Convlutional Layer UNET with RGB Cifar10 dataset and Class with Keras Model approach\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "class UNET(models.Model):\n",
    "    def __init__(self, org_shape, n_ch):\n",
    "        ic = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "        def conv(x, n_f, mp_flag=True):\n",
    "            x = MaxPooling2D((2, 2), padding='same')(x) if mp_flag else x\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            x = Dropout(0.05)(x)\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            return x\n",
    "\n",
    "        def deconv_unet(x, e, n_f):\n",
    "            x = UpSampling2D((2, 2))(x)\n",
    "            x = Concatenate(axis=ic)([x, e])\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            return x\n",
    "\n",
    "        # Input\n",
    "        original = Input(shape=org_shape)\n",
    "\n",
    "        # Encoding\n",
    "        c1 = conv(original, 16, mp_flag=False)\n",
    "        c2 = conv(c1, 32)\n",
    "\n",
    "        # Encoder\n",
    "        encoded = conv(c2, 64)\n",
    "\n",
    "        # Decoding\n",
    "        x = deconv_unet(encoded, c2, 32)\n",
    "        x = deconv_unet(x, c1, 16)\n",
    "\n",
    "        decoded = Conv2D(n_ch, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "        #decoded = Conv2D(n_ch, (3, 3), padding='same')(x)\n",
    "\n",
    "        super().__init__(original, decoded)\n",
    "        self.compile(optimizer='adadelta', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# UNET 검증\n",
    "###########################\n",
    "def plot_loss(history, title=None):\n",
    "    # summarize history for loss\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "###########################\n",
    "# UNET 동작 확인\n",
    "###########################\n",
    "\n",
    "\n",
    "def show_images(data, unet):\n",
    "    x_test_in = data.x_test_in\n",
    "    x_test_out = data.x_test_out\n",
    "    decoded_imgs_org = unet.predict(x_test_in)\n",
    "    decoded_imgs = decoded_imgs_org\n",
    "\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        print(x_test_out.shape)\n",
    "        x_test_out = x_test_out.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        print(x_test_out.shape)\n",
    "        decoded_imgs = decoded_imgs.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[:, 0, ...]\n",
    "        elif data.in_ch == 2:\n",
    "            print(x_test_out.shape)\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "        else:\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "    else:\n",
    "        # x_test_in = x_test_in[..., 0]\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[..., 0]\n",
    "        elif data.in_ch == 2:\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i in range(n):\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1)\n",
    "        if x_test_in.ndim < 4:\n",
    "            plt.imshow(x_test_in[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(x_test_in[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n * 2)\n",
    "        plt.imshow(x_test_out[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 1751s 44ms/step - loss: 0.0262 - val_loss: 0.0180\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 1737s 43ms/step - loss: 0.0118 - val_loss: 0.0094\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 1742s 44ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 4/10\n",
      "29184/40000 [====================>.........] - ETA: 7:04 - loss: 0.0090"
     ]
    }
   ],
   "source": [
    "in_ch=1\n",
    "epochs=10\n",
    "batch_size=512\n",
    "fig=True\n",
    "\n",
    "unet = UNET(data.input_shape, data.n_ch)\n",
    "\n",
    "history = unet.fit(data.x_train_in, data.x_train_out,\n",
    "                   epochs=epochs,\n",
    "                   batch_size=batch_size,\n",
    "                   shuffle=True,\n",
    "                   validation_split=0.2)\n",
    "\n",
    "if fig:\n",
    "    plot_loss(history)\n",
    "    show_images(data, unet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
