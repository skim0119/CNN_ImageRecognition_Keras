{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow - Tensorboard\n",
    "\n",
    "- #tensorboard\n",
    "\n",
    "references: https://github.com/golbin/TensorFlow-Tutorials\n",
    "\n",
    "텐서플로를 사용해서 사이즈가 큰 신경망 네트워크를 계산하다보면, 계산과정이 복잡하고 헷갈리기 마련입니다. 텐서보드는 이런 복잡한 계산과정을 조금이라도 이해하기 쉽게 하기 위한 도구입니다. 내부적으로 그래프, 이미지, 히스토그램 등 함수와 변수가 어떻게 변해가는지를 쉽게 볼수 있습니다.\n",
    "\n",
    "![텐서보드 예제](./images/TensorboardCNN1.png)\n",
    "\n",
    "## 텐서보드 실행\n",
    "\n",
    "```\n",
    "tensorboard --logdir=./logs\n",
    "http://localhost:6006\n",
    "```\n",
    "\n",
    "## 레이어\n",
    "\n",
    "레이어는 다음과 같이 설정합니다.\n",
    "\n",
    "``` py\n",
    "with tf.name_scope('layer'):\n",
    "    w1 = tf.Variable(tf.random_uniform([784,100], -1, 1), name='w1')\n",
    "    h1 = tf.nn.relu(tf.matmul(x, w1))\n",
    "    \n",
    "    tf.summary.histogram(\"x\", x)\n",
    "```\n",
    "\n",
    "한 레이어 안에 w1과 h1를 설정한 모습입니다. 텐서보드 안에서 w1과 h1은 한 레이어 안에 표현됩니다.\n",
    "\n",
    "tf.summary 안에 메소드를 사용하여 얻고싶은 값들을 지정할수 있습니다. 레이어 안에 같이 지정해줘야 합니다.\n",
    "\n",
    "### 스칼라\n",
    "\n",
    "``` py\n",
    "tf.summary.scalar(\"x\", x)\n",
    "```\n",
    "\n",
    "### 히스토그램\n",
    "\n",
    "``` py\n",
    "tf.summary.histogram(\"x\", x)\n",
    "```\n",
    "\n",
    "## 그래프 설정 및 표시하고싶은 텐서 설정\n",
    "``` py\n",
    "# 스칼라나 히스토그램으로 보여주려는 변수들 모음\n",
    "merged = tf.summary.merge_all()\n",
    "# 그래프와 텐서값 저장공간 설정\n",
    "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "```\n",
    "\n",
    "## 값을 얻고 저장\n",
    "``` py\n",
    "writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 숫자필체 판별 예제\n",
    "\n",
    "https://www.tensorflow.org/tutorials/layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\venv\\deepnn\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14772794299259862195, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5586505728\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 4966557896555366174\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Import Dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_data = mnist.train\n",
    "eval_data = mnist.test\n",
    "\n",
    "# Check Device\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bias2:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "global_step = tf.Variable(-1, trainable=False, name='global_step')\n",
    "increment_global_step_op = tf.assign(global_step, global_step+1)\n",
    "\n",
    "num_filters1 = 32\n",
    "num_filters2 = 64\n",
    "num_units1 = 7*7*num_filters2\n",
    "num_units2 = 1024\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='input')\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "with tf.name_scope('conv1'):\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,num_filters1], stddev=0.1), name = 'kernel1')\n",
    "    h_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME')\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[num_filters1]), name = 'conv_bias1')\n",
    "    h_conv1_cutoff = tf.nn.relu(h_conv1 + b_conv1)\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "with tf.name_scope('conv2'):\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal([5,5,num_filters1,num_filters2], stddev=0.1), name = 'kernel2')\n",
    "    h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding='SAME')\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[num_filters2]), name = 'conv_bias2')\n",
    "    h_conv2_cutoff = tf.nn.relu(h_conv2 + b_conv2)\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*num_filters2])\n",
    "\n",
    "with tf.name_scope('dense1'):\n",
    "    w2 = tf.Variable(tf.truncated_normal([num_units1, num_units2]), name='weight1')\n",
    "    b2 = tf.Variable(tf.constant(0.1, shape=[num_units2]), name = 'dense_bias1')\n",
    "    hidden2 = tf.nn.relu(tf.matmul(h_pool2_flat, w2) + b2)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    hidden2_drop = tf.nn.dropout(hidden2, keep_prob)\n",
    "\n",
    "with tf.name_scope('dense2'):\n",
    "    w0 = tf.Variable(tf.zeros([num_units2, 10]), name='weight2')\n",
    "    b0 = tf.Variable(tf.zeros([10]), name = 'dense_bias2')\n",
    "    p = tf.nn.softmax(tf.matmul(hidden2_drop, w0) + b0)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    t = tf.placeholder(tf.float32, [None, 10])\n",
    "    loss = -tf.reduce_sum(t * tf.log(p), name='loss')\n",
    "    train_step = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "    correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "    \n",
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "tf.summary.histogram('kernel1', W_conv1)\n",
    "tf.summary.histogram('kernel2', W_conv2)\n",
    "tf.summary.histogram('dense1', w2)\n",
    "tf.summary.histogram('bias1', b2)\n",
    "tf.summary.histogram('dense2', w0)\n",
    "tf.summary.histogram('bias2', b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "global_step: -1\n",
      "Step: 0,  loss: 23710.799 accuracy: 0.097\n",
      "Step: 1000,  loss: 1014.523 accuracy: 0.969\n",
      "Step: 2000,  loss: 772.287 accuracy: 0.975\n",
      "Step: 3000,  loss: 602.978 accuracy: 0.980\n",
      "Step: 4000,  loss: 467.697 accuracy: 0.984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./saved_models/tensorboard.ckpt-4999'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./saved_models')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 스칼라나 히스토그램으로 보여주려는 변수들 모음\n",
    "merged = tf.summary.merge_all()\n",
    "# 그래프와 텐서값 저장공간 설정\n",
    "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    \n",
    "print('Start Training')\n",
    "print('global_step: %s' % tf.train.global_step(sess, global_step))\n",
    "i = 0\n",
    "for step in range(5000):\n",
    "    batch_xs, batch_ts = train_data.next_batch(50)\n",
    "    feed_dict_train = {x:batch_xs, t:batch_ts, keep_prob:0.5}\n",
    "    feed_dict_test = {x:eval_data.images, t:eval_data.labels, keep_prob:1.0}\n",
    "    \n",
    "    sess.run([train_step, increment_global_step_op],\n",
    "             feed_dict=feed_dict_train)\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print('Step: %d, ' % sess.run(global_step),\n",
    "          'loss: %.3f' % sess.run(loss, feed_dict=feed_dict_test),\n",
    "          'accuracy: %.3f' % sess.run(accuracy, feed_dict=feed_dict_test))\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict=feed_dict_train)\n",
    "    writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "    \n",
    "saver.save(sess, './saved_models/tensorboard.ckpt', global_step=global_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
