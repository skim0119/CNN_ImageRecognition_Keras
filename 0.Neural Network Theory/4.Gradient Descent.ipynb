{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "- This note includes implementation of gradient descent method using Python 3 __without an assist of TensorFlow or Keras__.\n",
    "- Numpy python module is only tool for matrix calculation.\n",
    "- Simple Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression Model\n",
    "\n",
    "- The vector w act as a regression model.\n",
    "- Goal is move $w_0$, which is zero vector, to approach the coefficient of polynomial.\n",
    "\n",
    "$$\n",
    "y_n = (n^0, n^1, n^2, n^3, n^4)\\cdot\n",
    "\\begin{pmatrix}\n",
    "w_0 \\\\ w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4\n",
    "\\end{pmatrix}\n",
    "= \\sum_{m=0}^{4}w_mn^m \\\\\n",
    "\\textbf{y} = \\textbf{Xw} \\\\\n",
    "\\textbf{X} =\n",
    "\\begin{pmatrix}\n",
    "x_0^0 & x_0^1 & x_0^2 & x_0^3 & x_0^4 \\\\\n",
    "x_1^0 & x_1^1 & x_1^2 & x_1^3 & x_1^4 \\\\\n",
    "x_2^0 & x_2^1 & x_2^2 & x_2^3 & x_2^4 \\\\\n",
    "\\vdots\\\\ \n",
    "x_n^0 & x_n^1 & x_n^2 & x_n^3 & x_n^4 \\\\\n",
    "\\end{pmatrix}\n",
    ", \\quad\n",
    "\\textbf{w} =\n",
    "\\begin{pmatrix}\n",
    "w_0 \\\\ w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Method\n",
    "- Loss Function:\n",
    "$$\n",
    "E = \\frac{1}{2} \\sum_{n=1}^{12}(y_n - t_n)^2 \\\\\n",
    "E(\\textbf{w}) = \\frac{1}{2} \\sum_{n=1}^{12}\\left(\\sum_{m=0}^{4}w_mn^m - t_n\\right)^2 \n",
    "$$\n",
    "One of the key criteria of local minimum of function is the gradient $\\frac{\\partial E}{\\partial w_m} = 0$.  \n",
    "The gradient of function represent the direction where the maximum slope along the surface is.  \n",
    "Gradient descent method suggest the discrete approach to local minima by moving in the opposite gradient direction from any point along the surface.  \n",
    "$$\n",
    "\\textbf{w}^{\\text{new}}=\\textbf{w}-\\epsilon\\nabla E\n",
    "$$\n",
    "- $\\epsilon$ represent the rate of learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimizer\n",
    "\n",
    "- https://arxiv.org/pdf/1412.6980.pdf\n",
    "\n",
    "> __Algorithm 1__: Adam, our proposed algorithm for stochastic optimization. See section 2 for details, and for a slightly more efficient (but less clear) order of computation. $g_t^2$ indicates the elementwise square $g_t \\otimes g_t$. Good default settings for the tested machine learning problems are α = 0.001, β1 = 0.9, β2 = 0.999 and $\\epsilon = 10^−8$. All operations on vectors are element-wise. With $β_1^t$ and $β_2^t$ we denote β1 and β2 to the power t.  \n",
    "__Require__: α               : Stepsize  \n",
    "__Require__: β1, β2 ∈ [0, 1) : Exponential decay rates for the moment estimates  \n",
    "__Require__: f(θ)            : Stochastic objective function with parameters θ  \n",
    "__Require__: θ0              : Initial parameter vector\n",
    "```\n",
    "m0 ← 0 (Initialize 1st moment vector)  \n",
    "v0 ← 0 (Initialize 2nd moment vector)  \n",
    "t ← 0 (Initialize timestep)  \n",
    "while θt not converged do  \n",
    "    t ← t + 1  \n",
    "    g_t ← ∇_θ f_t(θ_t−1) (Get gradients w.r.t. stochastic objective at timestep t)  \n",
    "    m_t ← β_1 · m_t−1 + (1 − β_1) · g_t (Update biased first moment estimate)  \n",
    "    v_t ← β_2 · v_t−1 + (1 − β_2) · (g_t ^ 2) (Update biased second raw moment estimate)  \n",
    "    mb_t ← m_t/(1 − (β_1 ^ t) ) (Compute bias-corrected first moment estimate)  \n",
    "    vb_t ← v_t/(1 − (β_2 ^t) ) (Compute bias-corrected second raw moment estimate)  \n",
    "    θ_t ← θ_(t−1) − α · mb_t/(sqrt(vb_t) + e) (Update parameters)  \n",
    "end while  \n",
    "return θt (Resulting parameters)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
